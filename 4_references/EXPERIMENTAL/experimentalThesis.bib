
@article{particles8010018,
  author         = {Artero Pons, Maria},
  title          = {{ICARUS at the Short-Baseline Neutrino Program: First Results}},
  journal        = {Particles},
  volume         = {8},
  year           = {2025},
  number         = {1},
  article-number = {18},
  issn           = {2571-712X},
  abstract       = {The ICARUS collaboration employed the 760-ton T600 detector in a successful three-year physics run at the underground LNGS laboratory. In 2021, ICARUS started its new operation at Fermilab, collecting a substantial amount of neutrino events from the Booster Neutrino Beam (BNB) and the neutrinos at the Main Injector (NuMI) beam off-axis. These were used to test the ICARUS event selection, reconstruction, and analysis algorithms. ICARUS successfully completed its commissioning phase in June 2022, moving then to data taking for neutrino oscillation physics, aiming at first to either confirm or refute the claim by the Neutrino-4 short-baseline reactor experiment. ICARUS will also perform measurements of neutrino cross sections in LAr with the NuMI beam and several Beyond Standard Model studies. After the first year of operations, ICARUS will search for evidence of sterile neutrinos jointly with the Short-Baseline Near Detector, within the Short-Baseline Neutrino program. In this work, preliminary results from the ICARUS data with the BNB and NuMI beams are presented, both in terms of the performance of all ICARUS subsystems and the capability to select and reconstruct neutrino events.},
  doi            = {10.3390/particles8010018}
}

@phdthesis{Mawby:2023nws,
  author       = {Mawby, Isobel},
  title        = {{Optimisation of the search for CP-symmetry violation at the deep underground neutrino experiment}},
  reportnumber = {FERMILAB-THESIS-2023-11},
  school       = {University of Warwick, Warwick U., Warwick U.},
  year         = {2023}
}

@inproceedings{artero_pons_2024_13841852,
  author    = {Artero Pons, Maria},
  title     = {{Neutrino reconstruction analysis at ICARUS detector}},
  booktitle = {{Neutrino 2024}},
  month     = jun,
  year      = 2024,
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.13841852}
}

@inproceedings{Campani:2024_neutrinoBDT,
  author    = {Campani, Alice},
  title     = {{Track vs shower discrimination in the event reconstruction of the ICARUS experiment}},
  booktitle = {{Neutrino 2024}},
  month     = jun,
  year      = 2024
}

@inproceedings{Mawby:2025_FCCee,
  author    = {Mawby, I.},
  title     = {{Debugging Pandora: Insights from a Pandora developer}},
  booktitle = {{FCC-ee Workshop on Particle Flow Reconstruction}},
  month     = {9},
  year      = {2025}
}

@techreport{Nguyen:2023_cheatingPandora,
  author = {Nguyen, Vu Chi Lan },
  title  = {{How to Cheat Pandora}},
  number = {{SBN-doc-31192-v1}},
  month  = {may},
  year   = {2023}
}

@techreport{Triozzi:2025_impactNueReconstruction,
  author = {Triozzi, Riccardo },
  title  = {{Impact of reconstruction changes on a NuMI $\nu_\mathrm{e}$CC 0$\pi$ selection}},
  number = {{SBN-doc-41293-v2}},
  month  = {may},
  year   = {2025}
}

@techreport{Sotgia:2025_cheatingPandoraStatus,
  author = {Sotgia, Mattia },
  title  = {{Update on the status of Pandora reconstruction cheating tests}},
  number = {{SBN-doc-42066-v1}},
  month  = {jul},
  year   = {2025}
}

@techreport{Sommaggio:2025_updatesdEdxStudies,
  author = {Sommaggio, Nicola },
  title  = {{Updates on dE/dx studies}},
  number = {{SBN-doc-41770-v1}},
  month  = {jun},
  year   = {2025}
}

@techreport{Sotgia:2024d,
  author      = {Campani, Alice and Di Noto, Lea and Fava, Angela and Sotgia, Mattia},
  institution = {{ICARUS TPC Reconstruction WG}},
  title       = {{Update on the new training for track vs shower discrimination in Pandora}},
  number      = {{SBN-doc-37990-v1}},
  year        = {2024}
}

@techreport{ICARUS:2025_nuMuTechNote,
  author        = {Artero Pons, Maria and Campani, Alice and Cherdack, Daniel and Drielsma, Francois and Farnese, Christian and Gibin, Daniele and Hausner, Harry  and Larkin, Jacob and Mooney, Michael R and Mueller, Justin and Poppi, Francesco and Smith, Jacob A and Stanco, Luca and Totani, Dante and Varanini, Filippo and  Wolfs, Jean and Worcester, Elizabeth and Zennamo, Joseph and Zettlemoyer, Jacob},
  institution   = {{ICARUS $\nu_\mu$ oscillation task-force}},
  collaboration = {{ICARUS}},
  title         = {{ICARUS $\nu_\mu$ Disappearance Analysis Technote}},
  number        = {{SBN-doc-42799-v1}},
  month         = {aug},
  year          = {2025}
}

@article{DUNE:2025wti,
  author        = {Abud, A. Abed and others},
  collaboration = {DUNE},
  title         = {{Neutrino interaction vertex reconstruction in DUNE with Pandora deep learning}},
  eprint        = {2502.06637},
  archiveprefix = {arXiv},
  primaryclass  = {hep-ex},
  reportnumber  = {FERMILAB-PUB-25-0037-LBNF},
  doi           = {10.1140/epjc/s10052-025-14313-8},
  journal       = {Eur. Phys. J. C},
  volume        = {85},
  number        = {697},
  pages         = {697},
  year          = {2025}
}

@article{ronneberger2015unetconvolutionalnetworksbiomedical,
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  year          = {2015},
  eprint        = {1505.04597},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{10.1007/978-3-319-24574-4_28,
  author    = {Ronneberger, Olaf
               and Fischer, Philipp
               and Brox, Thomas},
  editor    = {Navab, Nassir
               and Hornegger, Joachim
               and Wells, William M.
               and Frangi, Alejandro F.},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
  year      = {2015},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {234--241},
  abstract  = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  isbn      = {978-3-319-24574-4}
}

@article{LeCun2015,
  author   = {LeCun, Yann
              and Bengio, Yoshua
              and Hinton, Geoffrey},
  title    = {Deep learning},
  journal  = {Nature},
  year     = {2015},
  month    = {May},
  day      = {01},
  volume   = {521},
  number   = {7553},
  pages    = {436-444},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  issn     = {1476-4687},
  doi      = {10.1038/nature14539}
}

@phdthesis{dellepianeBDT,
  type    = {{M. Sc.} thesis},
  title   = {{Study and training of a Boosted Decision Tree algorithm for track and shower discrimination in the {ICARUS} experiment}},
  author  = {Dellepiane, Stefano and Di Noto, Lea and Di Domizio, Sergio and Pallavicini, Marco},
  address = {Genova},
  school  = {Universit{\`a} degli studi di Genova},
  year    = {2023}
}