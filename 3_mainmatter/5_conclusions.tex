% !TEX root=../main.tex

\addchap{Conclusions}\label{chap:conclusions}

\dictum[Anonymous]{I conclude that when I'm done with my thesis, life will be better}
\vspace{1em}

% STRUCTURE

%% Description 
In the past twenty years several short-baseline anomalies hinted at the possibility of a fourth eV-scale ``sterile'' neutrino state, with the experimental evidence incoherent from one to another. The need to unravel the sterile neutrino picture led to the development of the SBN program. In the SBN program two functionally identical TPC detectors, the ICARUS and SBND experiments, are employed to measure with unprecedented sensitivity short baseline neutrino oscillations. ICARUS is the first experiment employing the LArTPC technology and was the largest LArTPC until the development of the {ProtoDUNE} detector. It is installed in the BNB baseline at a distance of \SI{600}{\m} from the neutrino source, collecting neutrinos also from the NuMI neutrino beam ${\sim}\SI{6}{\degree}$ off-axis. ICARUS operates at a shallow depth, covered by a \SI{3}{\m} thick concrete overburden reducing the impact of low-energy neutral interactions and the rate of cosmogenic interactions, alongside a Cosmic Ray Tagger system that ensures a $4\pi$ coverage of the detector. Data streams from the detector are analysed to extract the physical information with a wide set of tools, performing multiple operations, from the raw signal processing to higher-level reconstruction of the interaction happening inside the LAr active volume. 

This thesis focuses on a thorough study of the higher-level reconstruction of the interaction, with a primary focus on the Pandora framework. A large set of tools is involved in performing the event reconstruction, and different approaches are taken to ensure a robust result is achieved. One key task of the event reconstruction and signal identification pipeline is the identification, from the processed signal deposited on the TPC wireplanes, of the interaction components: all the final state particles in the interaction and their orientation in three-dimensional space are created building from their 2D projections on the readout planes, the interaction vertex is assigned, and the parent-daughter hierarchy is defined. 
In the context of the ICARUS experiment, two main frameworks are adopted: Pandora, which takes a more ``traditional'' approach to the event reconstruction task, providing hundreds of algorithms sequentially building up events, and SPINE, which provides an end-to-end optimisable machine-learning-based approach to the event reconstruction. Pandora has been the baseline for the event reconstruction within the SBN program since its first days. 

The highly modular approach of the Pandora event reconstruction framework allows algorithms within the reconstruction chain to be modified and replaced. This is exploited by a set of algorithms that take advantage of the MC information associated with simulated data to perfect a targeted aspect of the reconstruction: such an approach, called ``cheating'' in the Pandora framework, allows the estimation of the importance of the steps that are present in the Pandora event reconstruction chain. 

The first part of the work was devoted to thoroughly validating the impact of using these algorithms in the event reconstruction chain in different places, either as a standalone replacement of the nominal algorithm or cumulatively, replacing the ``nominal'' reconstruction algorithms up to a certain step of the sequence. Using a sample of events corresponding to an exposure of \SI{8e19}{POT}, corresponding to about \num{6000} $\PGnGm$CCQE Np interaction events inside the detector active volume, each algorithm was characterised in terms of its impact on downstream variables. This was crucial in determining how to test the impact of perfecting these algorithms on variables downstream of event reconstruction. 

It was concluded that almost all the tools are compatible with the current ICARUS offline analysis infrastructure, except for the algorithms responsible for creating the correct particle hierarchy. Issues upstream of this step, as highlighted by the examples in \autoref{fig:particleHierarchy}, together with the use of the true underlying particle hierarchy, showed that the algorithm responsible for creating the particle hierarchy fails most of the time, assigning almost all the particles relatively close to the interaction vertex as primary particles in the interaction. Identifying these downstream variables was crucial in determining how to test the impact of perfecting these algorithms on variables downstream of event reconstruction. 

Comparing the selected events with the different configurations, a method was developed to compute the efficiency of each stage of the Pandora reconstruction chain. The idea was to compare two configurations that differ by one step, which is cheated on one configuration and left nominal on the other. To decouple the impact of the particle identification step, happening downstream of the event reconstruction, a modified selection was developed. This made it possible to compute the efficiency of the particle identification and was key to computing the efficiencies of all the major steps involved in the event reconstruction chain. 

The results of this analysis, showing the efficiency for all the mjor steps of the reconstruction chain, \begin{equation*}
    \begin{aligned}
        \epsilon_\mathrm{reco.} =&\
        \epsilon_\mathrm{2D\ clusters} &\times&\ 
        \epsilon_\mathrm{vertex\ creation} &\times&\ 
        \epsilon_\mathrm{3D\ reco.} &\times&\ 
        \epsilon_\mathrm{particle\ class.} =\\  
        =&\ \SI{89.7(1.8)}{\percent} &\times&\ 
        \SI{91.9(1.6)}{\percent} &\times&\ 
        \SI{97.7(1.6)}{\percent} &\times&\ 
        \SI{98.6(1.5)}{\percent},
    \end{aligned}
\end{equation*} give space for some remarks. The first remark is that the stage of the reconstruction performing the interaction vertex creation and selection is one of the most critical steps of the reconstruction, and also one where some improvement (up to the ${\sim}\SI{8}{\percent}$ gap) is possible. 

Similarly, this study shows that there is great room for improvements in the algorithms involved in the stage that performs the 2D clustering of the hits on the wireplanes. However, as mentioned in previous paragraphs, it should be noted that clusters are improved downstream of the dedicated cluster creation algorithm, for example, in the three-dimensional reconstruction stage. So it is more correct to say that there is space for improvements in the stages encompassing bidimensional clustering and algorithms performing cluster refinements involved in downstream three-dimensional reconstruction. 

In addition to this work, an independent study on the impact of the vertex was conducted. Employing another event reconstruction configuration, where only the vertex reconstruction is cheated, the projected improvement impact was evaluated considering a perfect vertex reconstruction, leading to results coherent with the results presented in the first part of this work: the ${\sim}\SI{8}{\percent}$ improvement foreseen by cheating the vertex reconstruction is compatible with the efficiency loss in the vertex creation algorithm. The path for future developments, therefore, has to be focused on improving the vertex reconstruction, and in achieving such a result, further development in different points of the reconstruction chain is also needed, as highlighted by this work. 

In conclusion, this work had two main objectives. The first was to validate the implementation of the cheating tools within the ICARUS event reconstruction chain, showing their strong points and highlighting the steps that require more attention. The second was to demonstrate that this approach, which targets precise physics analysis, leads to meaningful results and provides a path to the next steps in improving the event reconstruction chain. 

%% 
%%